nx run account:serve - значит что мы хотим запустить проект account на serve
serve - это запуск для разработки

libs->interfaces->src
Вот мы закинули что-то в библиотеку
Всё что мы можем переиспользовать - должно быть в библиотеках
Мы не можем что-то взять из одного приложения и переиспользовать в другом, оно должно быть вынесенно библиотекой !
Теперь зайдём в apps->account->src->app->app.controller и попытаемся сделать импорт
import { IUser } from '@purple/interfaces'; //и это ссылка не на npm пакет, это будет ссылка на библиотеку внутри нашего проекта
import {IUser} from "@purple/interfaces" - это будет валидно
Зайдём в tsconfig.base.json
"paths": {
      "@purple/interfaces": ["libs/interfaces/src/index.ts"]
}
засчет этого у нас работает такой красивый алиас, он говорит что @purple/interfaces будет ссылаться на libs/interfaces/src/index.ts
Засчет того что у нас есть этот path, а в каждом из проектов если мы зайдем в tsconfig(apps->account->src->tsconfig), то мы увидем там что они ссылаются на base те:
"extends": "../../tsconfig.base.json",
то мы можем в любом месте где нам необходимо импортировать кусочек нашей библиотеки import {IUser} from "@purple/interfaces"

Теперь в папке app все удалим кроме app.module.ts
И как мы можем генерить какой-то модуль внутри нашего приложения ?
Мы можем это делать с помощью того же генератора
Вместо того что бы указывать что мы будем использовать генератор какого-то плагина, мы можем nx g module и нам понадобится модуль пользователя
только здесь единственая особенность что мы хотим сослаться не просто на users, а указать что мы находимся в папке app внутри
nx g module app/user --project=account
Вот в такой записи nx под собой вызовет cli и сгенерит нам модуль
Тоже самое будет и с контроллером и с сервисом !

Если нам нужно установить зависимости, то будет все точно так же как в обычных проектах - npm i bcryptjs


После того как мы создали фцию getMongoConfig() и добавили ConfigService и Mongoose в App.Module в зависимости - нам нужно дополнить наш interface в нашей либе libs -> interfaces -> src -> lib -> user.interface.ts
Интерфейс в либе - является основной состовляющей что бы не позволить нашему приложению развалиться, если мы будем переиспользоваться один и тот же интерфейс на Фронте, в микросервисах и так далее, на основе этого интерфейса мы будем базировать как и модели так и ентити
То-есть мы и в user.entity и user.model везде имплементируемся от IUser

//
Как между собой обмениваются микросервисы
Есть два типа общения: синхронный и асинхронный
Синхронный - если 1к1 то это запрос и ответ
Асинхронный - если брать 1к1, те один микросервис может запрашивать другой микросервис, это асинхронный запрос/ответ и уведомления(представь что есть пользователь и нам нужно его предупредить что курьер к нему поехал и нам всё равно что он нам овтетит, нам нужно его предупредить). 1-* то подписка на событие; событие с ожидаением ответа
1к1 - это когда у нас есть микросервис отзывов, а нам нужно получить пользователей для этого отзыва, до мы явно идём к микросервису пользователю и получаем нужные нам данные
1-* - один ко многим
Синхронный - когда мы блокируем весь потом и ждём ответа
Асинхронный - когда нам без разницы и мы ничего не блокируем

Что мы передаём в этих сообщениях ? Форматы Данных
Текстовый                           Биннарный
-простой для чтения                 -компактность(то-есть вместо открытого джсона мы кодируем)
-простая обратная совместимость     -сильная типизация(это может быть и минусом потому что тяжелее поддерживать обратную совместимость в контрактах)
json,xml                            Protobuf

Контракты
 --->            export class Request {   --> SERVICE --> export class Response { access_token: string }  -->
                    @IsString()
                    login: string;

                    @IsString()
                    password: string;
                 }
Контракты - это некоторая договоренность о том как должны выглядеть Запрос и Ответ в Микросервисах. В нашем случае мы для валидации будем использовать декораторы + классы тайпскрипта для типизации. У нас есть контракт как должен выглядеь Request и Response как выше
Эти контракты должны распростронятся между микросервисами, те мы не можем его поместить только в один микросервис и всё, о том как и что нужно отправлять должны знать все микросервисы. По-этому эти контракты должны шарится в виде библиотек если мы исользуем монорепозиторий, либо они должны быть опубликовану в нпм что бы мы могли посмотретьь последнею версию контракту и как она работает.
Большое преимущество типизированных контрактов(тс, джава, го) это то что при обновление контрактов мы сразу видим что у нас ломается, если бы мы типизировали только в рантайме - то это была бы большей проблемой


Транспорт для коммуникации
HTTP, gRPC, RabbitMq, redis, kafka

HTTP, gRPC относятся к типу обменну синхронному, там где 1к1 Запрос/Ответ
gRPC - это больше модифицированный формат, отдаленный вызов процедур. Этот формат является стандартом для транспорта в микросервисаху во многих языках, но у него есть все минусы и плюсы http
Плюс http - это его готовая документация, а минус что он не асинхронный

RabbitMq, redis, kafka - Это брокер сообщений

RabbitMq - построенн на протоколе mqp и позволяет иметь огромную пропускную способность(прям молнеиностную). Так же возможность сохраннеия персистентности и на нём хорошо делать микросервисы

redis - ин мемори дата бейз(база данных находящиеся внутри памяти), которая позволяет хранить какие-то данные и работать с очередями. Там есть redis папса которая позволяет обмениваться сообщениями. По-сути это такая же шина, когда один сервис заходит и кладёт сообщение в очередь, а второе разбирает. Редис - более прост с точки зрение паттерна взаимодействия чем RabbitMq(а RabbitMq позволяет реализовать огромное число паттернов асинхроного взаимодействия) а у redis - это простая очередь, редис быстрый(потому что это ин мемори дата бейз, редис упал и мы потеряли сообщение, а если РеббитМq упал то мы можем сказать что для важных сообщений нужно персистентность сохранять, по-этому РебитМq с точки зрения обмена и надёжности лучше чем redis)

kafka - стандарт надёжности. Позволяет сохранять сообщения в специальные очереди, при этом очереди имеют специализированную структуру. В РеббитМq если мы сообщение отработали - то мы его выкинула, а в Кафке сохраняется весь лог(очередь) сообщений и если нам нужно мы можем отмотать на 10 сообщений назад и повторить все эти 10 вызовов. Но теряет Кафка в производительности в отличие от Реббита, потому что работает с очередями, да еще и которые воспроизводимы. По-этому если нам не нужна скорость обмена и у нас синхронная архитектура где всё идет друг за другом то Кафка !
Можно в проекте использовать и то и то, что бы Реббит занимался теми сообщениями которые нуждаются в скорости, а Кафка которые нужно повторять


// Простая коммуникация
Представь что у нас есть два микросервиса, один стучится во второй и получает нужные данные и отдает пользователю
Теперь представим что один микросервис падает и начинается НАКОПЛЕНИЕ набор запросов, пользователи дальше всё запрашивают и запршивают, мы всё ждём ждём а ответа нет, еще ждём и ответа тоже нет, и так накапливается все больше запросов и у нас начинается кушать память потому что у нас синхронные http запросы

У нас первый сервис из примера Антона запущен на localhost:3000 а второй 3001
И первый сервис должен знать что второй запущен на localhost + имеет соотвествующий порт 3001
Теперь представим что у нас таких сервисов около 10 и мы не всегда знаем поднялся ли сервис, а если поднялся то на каком хосте

Проблемы
-Отказоустойчивость при падение одного из сервисов
-Service Discovery - понимание куда отправляется запрос
-Слабая доступность: 10 сервисов с доступностью 98% - общая доступность около 80%

Решение частичной недоступности
1)
Service 1 Proxy   timeout--->  Service 2
То-есть если у нас в таймауте который мы указали(2-3 секунды к примеру) после запроса Сервис 2 не отвечает в течение времени указанного в таймауте, то нам нужно этот запрос просто обрывать
Но у Proxy автоматический фейл при накаплевание сообщений до limit - те пока Сервис2 не отвечает начинается накапливаться и рушится память в Сервисе 1 и что бы избежать ошибку нужно сразу же всё обрывать когда кство запросов дойдёт до этого limit

2) Service discovery - саморегистрация
API       -->         Payments
стрелка к Registry от API и Payments
          Registry
То-есть наш сервис при поднятие(к примеру Пеймент) идет в какой-то Регистри и записывает в этот Registry что я поднялся на таком-то АЙПИ
и когда сервис АПИ хочет получить данные из Пеймент, она идёт к Регистри и смотрит на каком АЙПИ распологается Пеймент и уже идет за ним

Service discovery - авто регистрация

API         -->       Payments
          Registry
Router                Discovery
то-есть АПИ идет к пеймент стрелкой и стрелкой к Router и стрелка от Router и Дискавери в Пеймент
Когда у нас поднимается какой-то Сервис - он поднимается в каком-то окружение, к примеру Докер, как только мы стартовали контейнер с нашим сервисом Пеймент, Докер сразу понимаеь что это пейментс и он запущен на каком-то виртуальном Докер айпи и сам автоматически с помощью своего Discovery сохраняет эту информацию
Когда АПИ хочет обратится к Пеймент то вместо того что бы прямо идти к Пеймент - мы идём в некий Роутер(внутренний днс) разруливает что Пейментс у нас должен относится к этому АЙПИШНИКУ и запрос идет на Пейментс
Такая авторегистрация позволяет избежать нам дополнительного кода для ручной регистрации, мы не должны сами регистрировать сервисы, а за нас всё это делает наша внутренея система Докер или Кубернетис

Когда использовать синхронную модель
-небольшой набор сервисом со слабой связанностью
-есть готовый сервис дискавери
-хочется использовать преимущество документации http(swagger)


// Комуникации через Брокера(асинхронно)
Простая отправка через брокер:
АПИ     НЕТ-->     Payments
lib             lib

      Broker
      Channel
То-есть теперь АПИ не идет на прямую к Пеймент, а идёт к Брокеру.
Всё что нужно знать Сервису АПИ что где-то существует Броккер, он может быть на том же хосте или на другом(не принципиально), АПИ знает только что что бы выполнить какуе-то задачу - ему нужно отправить в этот Брокер сообщение
При этом сам АПИ мокается не понятно где и об этом никому знать не нужно потому что апи сам подключается к нашему брокеру
Channel - это некий инбокс(канал) куда мы кладём сообщение

Асинхронный запрос/ответ
Reply channel(Header(correlationID), Body) --> API(lib) --> Request channel(Header(correlationId, reply channel), Body) --> Payment(lib) --> обратно в Reply channel и так круговая зависимость

Если в синхронном запросу мы дернули апи и получили ответ, то здесь мы кладём сообщение и понимаем что через какое-то время получим ответ
correlationID - id сообщение по которому мы можем соотнести ответ
reply channel - канал куда нужно ответить, так как у нас асинхронно всё мы должны указать куда должен прийти ответ

Уведомление
Course(lib) --> Request Channel(Header, Body) --> Payments(lib)

Теперь паттерны 1к* (до этого были примеры 1к1)
Подписка на событие
Course(lib) -> CourseEvent channel  -> и в Payments и в Notification
То-есть впринципе подписка на событие похожа с предыдущим Уведомление, единсветнное отличие что сообщение доходит не только в Пеймент но и в Нотификейшен

Событие с ожидаение ответа
Course(lib) -> CourseEvent Channel(Header(correlationID, reply channel), Body) -> и в Payments и в Notification -> а Payments и Notification уже в CourseEvent ReplyChannel(Header(correlationID, author), Body) -> а тот обратно в Course(lib)
Обрати внимание что в CourseEvent ReplyChannel(Header(correlationID, author), Body) так же содержит correlationID что бы соотнести его с исходныи сообщением, а так же уже есть автор что бы соотнести его что это сообщение с correlationID ответ на сообщение из Payments, а другое сообщение это correlationID из Notification

Что дают БРОКЕРЫ
-слабую связанность сервисов(сервисы не знают друг от друге, им всё равно сколько их слушает сервисов)
-буферизация сообщения. Представим что у нас есть http запрос из одного сервиса к другому, когда мы генерим 1000 коннекшенов что бы отправить http то у нас сразу идет попытка обработать 1000 событий на Сервисе 2 куда пришло эти 1000 коннекшенов, чем больше загрузка - тем больше сообщений нам нужно обрабатывать, но брокеры могут буферизировать сообщения, мы можем сказать что CourseEvent Channel будем потихоньку накапливать евенты и потихоньку по 32 по 16 сообщений отдавать в Пеймент и в Нотификейшен, те немного обработали и взяли следущую
-разные паттерны коммуникации, то-есть 1к* + уведомления, а не только 1к1
-персистетность(опционально). Представим что мы отправляем запрос на какуе-то оплату и у нас пропал свет, то-есть сетка отвалилась и наш запрос просто потерялся, потому что это http запрос, он сущестует пока у нас есть сети и возможность получить http запрос. Но большинство брокеров реализуют персистетность, мы кидаем сообщение к Брокеру, после этого у нас упал конечный сервис и брокер будет держать это сообщение пока тот сервис не поднимится и не разберёт его. Более того если мы кинули сообщение у нас брокер упал, то не страшно потому что когда поднимится сервер, брокер востановит своё текущее состояние с текущими сообщениями и продолжит работу. Лучше всего с этим справляется kafka и RabbitMQ тоже имеет такую возможность

Проблемы
-работа с несколькими инстенсами сервиса. Когда у нас брокер - нам нужно понимать как он будет работать в случае если два сервиса платежей, не нужно дублировать сообщения, нам нужно их как-то равномерно расспределять. В http такого нет, мы кидаем одному Сервису запрос, получаем ответ и все работает
-повторные сообщение при падениях. Брокеры доставляют сообщение хотя бы один раз, те теоритечски может быть сообщение доставленно больше одного раза
-отправка сообщения в транзакции. Иногда нам необходимо 100% обезпечить отправку сообщений вместе с записью Базы Данных и если этого не произоёдет и мы запишем в базу данных а сообщение не отправится, то будут неконсистентные данные

Решение этих проблем
1)Несколько инстансов
Course(liv) -> CourseEvent Channel(Round Robin) -> отправка 1к* в Payments1 и Payments2
Мы можем сказать в RabbitMQ что данный канал поддерживает раздачу Round Robin и когда нам сюда приходит сообщение то первое сообщение уйдет Сервису1 второе Сервису2 третие сново Сервису1

2) Повторные сообщение
Course(lib) -> CourseEvent Channel(Round Robin) -> ack nack NOT-> Payment1 , но нормально дойдёт сообщение до Payment2
ack - акнолежж
nack - неакноледж
Эти ack и nack помогают сказать что сообщение обработано и его можно удалить из очереди, либо не обработанно и нужно вернуть в очередь
Вообще хорошей практикой является сделать проверку на повторное сообщение, который будет обрабатывать эти случаи

3)Отправка сообщение в транзакции
Course    транзакция-> Outbox(База данных) и транзакция в Data(база данных) -> lib идет в Outbox для забора данных для отправки -> course event channel
Это паттерн Outbox: когда нам нужно отправить сообщени и записать что-то в БД то мы одновременно делаем транзакционную запись в Data - это то что нам нужно сохранить и в дополнительную спомагательную табличку Outbox которая обезпечивает наличие списка сообщения и их статуса отправки.
К примеру мы хотим поменять статус платежа и выслать сообщения о том что нужно выслать аудинтификацию, то мы в аутбоксе говорим что нужно изменить статус платежа и у нас data и outbox консистентные

// Минимализация синхронности
Проблема
Купить курс -> API -> проверить что курс не куплен и пойти в Account
так же API идет в Course что бы получить цену
и АПИ идет в Payment что бы Получить id платежа
Проблема в том что отказоустойчивость здесь не как в монолите 98%, а 98% на каждый сервис, то-есть у нас есть 4 сервиса и отказоустойчиовть уже 90 процентов. Если у нас ляжет Сервис Курсов, то наша Апишка после того как сходила в Account, пойдет в курсы и ляжет

Решение
Первое что делаем не куда до этого не идя - Создать id покупки и вернуть. То-есть мы на фронт пользователю отдаём какой-то Лоадер и переодически по этому id пытаемся понять что-то произошло или нет. То-есть мы вгновенно вернули из АПИ и все, нам нужен только один сервис что бы вернуть что то на фронт
Дальше все что будет происходить ниже - это уже будут асинхронные операции
Купить курс -> API -> проверить что курс не куплен и пойти в Account
так же API идет в Course что бы получить цену
и АПИ идет в Payment что бы Получить id платежа
Синхронная операция - Сразу пойти в Payment и проверять по ID покупки, появился ли ID платежа и вернуть при наличии

// Устройство RabbitMQ
                        --> Queue -> Subscriber
Publisher --> Exchange
                        --> Queue -> Subscriber
Паблишерем мы будем называть того кто публикует сообщение
Subscriber - будет подписывать на получение этого сообщения
Exchange - обменный ящик
Queue - очередь

Термины:
Exchange - сюда кладутся сообщения
Queue - очерель куда перенаправляются сообщения
Routing key - маршрут передачи сообщения 
Binding - связь очередь с маршрутом. Чтобы Exchange понимал по какому Routing key класть какую Queue - существует Binding
Channel - канал передачи/приёма сообщения 
Connection - соединения клиента к RMQ. В connection будет показывать все connectionы всех сервисов. Так как у нас rabbitmq развёрнут не в Кластере то у нас будет только один инстенс. Мы реббитмкю можем сделать класстерным(2-4 инстенса которые объединяютя в один кластер)

Структура сообщений - то что мы передаём при создание сообщения
Routing key  -->  get.users.query
Header       -->  format='pdf' save='yes'
Properties   -->  app_id='users' reply_to='me'
Payload      -->  {
                    from_email: 'rus@gmail.com',
                    from_name: 'Ruslan'
                  }

Очередь
Типы очередей бывают двух видео classic и quorum(на сколько наши сообщения будут персистентны относительно кластера RabbitMq, те это новый тип очереди который позволяет делать персистентным едюробл в случае падение одного из кластер)
Durability - означает что очередь будет сохранена после перезапуска

Мы создалди queue и exhacnge и пока exhacnge не знает как доставлять сообщения в очередь
Нам нужно зайти на exchange который мы создали и у нуго выбрать bindings и забиндить его на ту очередь которую мы создали
А так же мы указали какой ключ должен быть для очереди которую мы создали

После того как мы отправили сообщение в exchange у нас это сразу же показалось на графики, но если мы зайдем в очередь то увидим что у нашей очереди появится поле ready 1 то-есть туда попало сообщение но никем не разобранно
Unacked - сообщение взято но не обработано
Total - всего

Что бы получить это сообщение и если бы мы писали микросервисы то нужно было бы заходить в consumers, но так как мы тестируем то в get message
ack mode - nack message requeue true(взляи сообщение, посмотрели и положили обратно), automatick ack(мы сообщение разберем и оно исчезнет из очереди)

Важно поговорить в структуре сообщение о Properties потому что они крайне важны что бы понимать а что нам дальше делать с этим сообщением
Свойства сообщения
1) content_type, content_encoding, type(к примеру что тип контента бинарный или небинарный)
2) priority, expiration(к примеру если сообщение не разберут за минуту то оно не будет валидным)
3) timestamp(штамп времени и отправки сообщения)
4) correlation_id(это индификатор сообщения по которому мы можем в дальнейшем если нам не это сообщения ответят то понять что это ответ конкретно на это сообщение), reply_to, message_id. Здесь распологаются части которые отвечают за доставку сообщения
5) user_id, app_id, cluster_id

Свйоства очереди
Durable - после перезапуска очередь сохранится 
Exsclusive - очередь может использоваться только 1ым подключением и удалится после отключения
Auto-delete - удаляется после потери последнего потребителя
Arguments - доп аргументы(длина, приоритет и тд)

Реализация запрос/ответ
Publisher(здесь мы пишем rounting_key:my_route, properties: {correlation_id: 1, reply_to: 'ReplyQueue'}, payload: {request}) -> Exchange(binding my route) -> Queue -> Subscriber(properties: {correlation_id: 1 }, payload: { request } то-есть наш Subscriber из-за того что ему пришел от Publishera нужный нам reply_to то Субскрайбер разбирает это сообщение и на прямую кладёт его в ReplyQueue. Он уже не пойдет через Exchange потому что здесь одна конкретная очередь одного конкретного сервиса) -> ReplyQueue(exlusive - что бы никто не мог к ней еще подключится и мы получили бы ответ не с нужного сервиса) -> обратно в Publisher - и тут нужно понимает что в Паблишера может приходить ответ не только от одного Subscriber а из многих микросервисов, но по correlation_id он поймет кто ему ответил

Реализация уведомления
Publisher  -->  Exhacnge --> Queue1 -> Subscriber
                         --> Queue2 -> Subscriber
publiser в свою очередь указывает routing_key:my.event и payload
exchange - binding: my_event
и тут все быстро так как у нас нет reply_to мы просто расспечатаем наше сообщение и закончим процес


// Типы exchange
direct, fanout, headers, topic

1) Direct
Publisher  -->  Exhacnge --> Queue1 -> Subscriber
                         --> Queue2 -> Subscriber
publiser в свою очередь указывает routing_key и payload
exchange - binding: my_event
То-есть что делает Direct - как только в него попадает сообщение с роутингом к примеру routing_key: my.event то он в точности метчит все биндинги которые тоже равны my.event то-есть мы получаем binding:my.event, то-есть роутинг кей должен точно совпадать с биндингом
Здесь всё просто с пониманием - мы хотим отправить туда и оно туда попадёт

2) Topic 
Publisher(rounting_key: my.event, payload: { info })  -->  Exhacnge(binding: *.event)  --> Queue1 -> Subscriber
                                                                   binding: my.*       --> Queue2 -> Subscriber
* - любое число
# - любое число слов или пусто

Как только мы отправляем rounting_key: my.event мы можем отправить в ту очередь которая подписывается на этот Роутинг key с определенным паттерном. Паттерн можно задавать некоторыми символами: * и #
То-есть наш my.event будет разобран тем кто к нему забиндится либо по *.event либо my.*
Всегда лучше выбирать между Топиком и Директом именно Топик потому что он более гибкий и предсотавляет больше возможностей и в топике всегда можно сделать то что в директе

3) Fanout
Publisher(rounting_key: any, payload: { info })  -->  Exhacnge(binding: event)  --> Queue1 -> Subscriber
                                                                   binding: my  --> Queue2 -> Subscriber
Отправляем всем сообщение не смотря на routing_key
То-есть всем кто прибиндился, то-есть не смотря на то что у одного binding: event а у второго my, то так как routing_key: any доставится и туда и туда

4) Headers
Publisher(header:format=pdf, type=report, payload: { info }) -->  Exhacnge(format=bin type=report) NOT!--> Queue1 -> Subscriber
                                                                           format=pdf type=report  YES --> Queue2 -> Subscriber
Нам всё равно какой у нас routing_key, а смотрит на то что лежит в ЗАГОЛОВКАХ
То-есть сообщение доставится только тем очередям у которых в подписке будет такой же формат pdf как у нас в publisher
Headers нужно для того что бы прям очень тяжелые а разбитые домменые области контролировать

Оставшиеся очереди которые мы не можем создать но которые присутствуют в RabbitMq
1) Default 
Publisher(rounting_key: Queue1, payload: { info })  -->  Default  YES--> Queue1 -> Subscriber
                                                                  NOT--> Queue2 -> Subscriber
Дефолтная очередь позволяет почти на прямую публиковать в очередь, мы тут явно сказали что хотим отправить в очередь 1

2) Dead letter - собирает все мёртвые сообщения

Publisher(rounting_key: my.key, payload: { info }) --> Exchange  NOT-> Queue1 -> Subscribe
                                                                 NOT-> Queue2 -> Subscribe
                                                                 YES-> DEAD LETTER
То-есть когда мы публикуем смс и оно не подходим не к одной из очереди то с ним нужно что-то делать и мы отправляем его в Dead Letter

3) RabbitMq Trace. У нее стоит Internal - yes тоесть клиенты не могут на прямую публиковать сообщения, мы можем использовать только биндинги exchange to exchange, те мы можем создать биндинг на ДРУГОЙ Exchange.
Благодаря тому что мы можем прибиндится к exchange после того как кто-то на этот exchange выслал смс - мы можем получить копию этого смс, мы можем прибиндится ко всем очередям, копировать смс и использовать их для логгирования 


// Администрирование RabbitMq
1) Если у нас постоянно весят сообщения в overview то возможно у нас повисли какие-то consumer


// Добавление библиотеки контрактов
нам нужно перенести регистердто и логиндто с аус.контроллера в полноценный нормальный контракты
nx g @nrwl/nest:lib contracts

мы удалим в libs->contracts->src->lib->contracts.module потому что он нам не понадобится

Как нам теперь разбить на контракты, так как у нас единный контракт на все микросервисы, а здесь(libs->contracts->src->lib) мы их розмещаем потому что это может шерится на все микросервисы и все микросервисы могут иметь к нему доступ, по-этому мы делаем именно контракты
А внутри Либы мы сделаем папки по сервисам
К примеру: у нас первый сервис который мы делали назывался account, по-этому первую папку в Либе мы создадим аккаунт и в этом аккаунте libs->contracts->src->lib->account уже будут распологаться КОНТРАКТЫ
Контракт - это по сути куда отправлять, что отправлять и что получать назад
Один контратк - один файл


// nestjs-rmq
npm i nestjs-rmq
Подключаем Модуль rmq в app.module котора в apps->account->scr->app


// Стратегии реализации API
Микросервис как точка API
веб сайт    /get-courses -->       Courses 
веб сайт    /get-paid-courses -->  Payments
APP         /login -->             Users 
То-есть если мы постучимся по get-courses выдаст нам список всех курсов, то-есть мы делаем кучу маленьких апишек и каждая по запросу отдаёт свои данные
Проблема в том что аграгации этих данных нам прийдет отдавать на клиент: к примеру мы хотим получить платные курсы(какие есть у пользователя платные курсы) и дополнительно информацию по этим курсам что бы вывести карточки этих курсов, в результате мы должны получить все оплаченные курсы + получить все курсы и сделать join. Если у нас будет 100-1000 элемнетом которые нужно джоинить - будет плохо
А если у нас появится еще мобильный клиент типа APP то нужно будет кроме веба повторять код для мобилки

Паттерн API getaway

Веб-сайт                            get.courses-->          Courses
            get-my-courses--> API   get.paid.courses-->     Payments
APP                                 login-->                Users

У нас централизованная АПИ, которая принимает запросы от всех клиентов
Нам не нужно в таком паттерне дублировать логики, делать join на фронтенд и тд
Проблемы-проблема разделение логики. У нас может получится огромная монолитная апи и маленькие сервисы котоыре будут отдавать данные

АПИ ничего не должна знать о бизнес-логики 
Что выносить в апи:
-валидация авторизации
-ограничение числа запросов
-кэширование
-сбор метрик
-логирование и пометка запросов


BFF(Backend for frontend)

Веб-сайт    --> Web API          get.courses       -->    Courses
                                 get,paid.courses  -->    Payments
App         --> Mobile API       login             -->    Users

То-есть фронт сам себе пилет апишки для удобства
Преимущество в том что вместо того что бы реализовывать логику которая подходят как и для Веба так и для приложения
То-есть мы делаем веб - мы под себя сделали АПИ
Мы делаем моиблку - мы под себя сделали мобилку

Проблемы:
-дублирование кода 
-можно сделать ту же проблему что в АПИ getaway


// Паттерны получения данных

No CQRS     CRUD->    Domain     -> Database 
В этом паттерне нам что мы сделать CRUD опперацию(create, read, update, delete) мы идём к нашему огромному монолиту Domain и берём данные из БД

CQRS        CUD->     Domain    ->   Database
            R  ->     Query     ->   View
И еще одна стрелочка от Domain event-> Query

Операцию read мы выносим, потому что то как мы хотим прочитать данные - могут не совпадать с тем как мы их храним
У нас будет доп модель Query который нам будет читать данные
Когда у нас происходит какое-то доменное событие типа создания(апдейт, делит или криейт) то мы записываем в бд эти изменения и генерим события
Теперь допустим что у Курсов поменялось название и это от Domain эвентом(event) уходит к Query, а Query в свою очередь скажет что я получил обновления и запишу обновленив свое view

Пример для микросервисов 
Приходят юзер и хочет посмотреть свою историю покупок и он http запросом приходит в некий Purchase History, это может быть отдельный микросервис или отдельный модуль в апишке который хранит эту view. При этом Purchase History может быть частью какого-то микросервиса или частью АПИ
Этот микросервис имеет как в пред примере свою базу данныз View Database
Как эти данные собираются ? У нас есть три сервиса: Courses, Payments, User они важны что бы отображать наш Purchase History
И каждый раз когда у одного из сервиса происходит какое-то доменное событие - то они генерят event: к примеру мы создаем нвоый курс, тот записался в бд и сказал что он изменился и всех вокруг заинтересованным говорит что я изменился -> дальше Курс сегенерит евент что я создался или обновился в свою очередь Пеймент скажет что у него изменился статус платежа на оплачен и что-то еще поменяется Юзера
Все эти евенты попадают в обработчик Purchase History - это легко реализовать с помощью Реббита где мы подписываемся на доменные события каждого нам нужного сервиса и по каждому из этих событий мы в view database будем менять или обновлять данные
а когда к нам приходит пользователь с запросом на историю покупок - мы просто отдаём ему эти View

//
 nx g @nrwl/nest:app - мы создали в apps новую папку api и сразу же обновились workspace.json